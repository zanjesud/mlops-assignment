name: Data-Driven ML Pipeline

on:
  push:
    paths:
      - 'data/raw/iris.csv.dvc'
    branches:
      - develop
      - master
  workflow_dispatch:
    inputs:
      force_promotion:
        description: 'Force promotion to production'
        required: false
        default: false
        type: boolean

permissions:
  contents: write
  pull-requests: write
  packages: write
  actions: read

env:
  DOCKER_HUB_USERNAME: ${{ secrets.DOCKER_HUB_USERNAME }}
  DOCKER_HUB_TOKEN: ${{ secrets.DOCKER_HUB_TOKEN }}

jobs:
  data-validation-and-training:
    runs-on: ubuntu-latest
    name: "Data Validation & Model Training"
    
    outputs:
      model_trained: ${{ steps.training.outputs.model_trained }}
      run_id: ${{ steps.training.outputs.run_id }}
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Debug - Check what triggered this workflow
        run: |
          echo "Event name: ${{ github.event_name }}"
          echo "Ref: ${{ github.ref }}"
          echo "Files changed in this push:"
          git show --name-only --pretty=format: HEAD | grep -v '^$' || echo "No files found"
          
          echo "Checking if iris.csv.dvc exists and was modified:"
          if [ -f "data/raw/iris.csv.dvc" ]; then
            echo "‚úÖ iris.csv.dvc file exists"
          else
            echo "‚ùå iris.csv.dvc file not found"
          fi
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install uv
        run: pip install uv
      
      - name: Create virtual environment
        run: uv venv .venv
      
      - name: Install dependencies
        run: uv pip install -e .
      
      - name: Create necessary directories
        run: |
          mkdir -p logs artifacts data/processed models/production_model
      
      - name: Setup DVC and pull data
        env:
          GDRIVE_CLIENT_ID: ${{ secrets.GDRIVE_CLIENT_ID }}
          GDRIVE_CLIENT_SECRET: ${{ secrets.GDRIVE_CLIENT_SECRET }}
        run: |
          # Configure DVC with secrets (ensure they are strings)
          uv run dvc remote modify gdrive gdrive_client_id "$GDRIVE_CLIENT_ID"
          uv run dvc remote modify gdrive gdrive_client_secret "$GDRIVE_CLIENT_SECRET"
          
          # Pull updated data
          echo "Pulling data with DVC..."
          uv run dvc pull data/raw/iris.csv.dvc || {
            echo "DVC pull failed, trying to authenticate..."
            uv run dvc remote modify gdrive gdrive_use_service_account false
            uv run dvc pull data/raw/iris.csv.dvc
          }
          echo "Data pulled successfully"
          
          # Validate data exists
          if [ ! -f "data/raw/iris.csv" ]; then
            echo "Error: iris.csv not found after DVC pull"
            exit 1
          fi
          
          echo "Data validation passed"
      
      - name: Train model on updated data
        id: training
        run: |
          echo "Starting model training on updated data..."
          
          # Run training script
          RUN_ID=$(uv run python scripts/train_on_data_update.py)
          
          if [ $? -eq 0 ] && [ ! -z "$RUN_ID" ]; then
            echo "model_trained=true" >> $GITHUB_OUTPUT
            echo "run_id=$RUN_ID" >> $GITHUB_OUTPUT
            echo "Model training successful. Run ID: $RUN_ID"
          else
            echo "model_trained=false" >> $GITHUB_OUTPUT
            echo "Model training failed or did not meet criteria"
            exit 1
          fi
      
      - name: Upload training artifacts
        if: steps.training.outputs.model_trained == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: training-artifacts
          path: |
            artifacts/
            logs/
          retention-days: 30

  promote-to-staging:
    runs-on: ubuntu-latest
    name: "Promote to Staging"
    needs: data-validation-and-training
    if: needs.data-validation-and-training.outputs.model_trained == 'true'
    
    outputs:
      staging_promoted: ${{ steps.staging.outputs.staging_promoted }}
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install uv
          uv venv .venv
          uv pip install -e .
      
      - name: Download training artifacts
        uses: actions/download-artifact@v4
        with:
          name: training-artifacts
      
      - name: Promote model to staging
        id: staging
        env:
          RUN_ID: ${{ needs.data-validation-and-training.outputs.run_id }}
        run: |
          echo "Promoting model to staging..."
          
          # Run staging promotion
          if uv run python scripts/promote_to_staging.py --run_id $RUN_ID; then
            echo "staging_promoted=true" >> $GITHUB_OUTPUT
            echo "Model promoted to staging successfully"
          else
            echo "staging_promoted=false" >> $GITHUB_OUTPUT
            echo "Failed to promote model to staging"
            exit 1
          fi
      
      - name: Upload staging artifacts
        if: steps.staging.outputs.staging_promoted == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: staging-artifacts
          path: |
            artifacts/
            logs/
          retention-days: 30

  promote-to-production:
    runs-on: ubuntu-latest
    name: "Promote to Production"
    needs: [data-validation-and-training, promote-to-staging]
    if: |
      needs.promote-to-staging.outputs.staging_promoted == 'true' && 
      (github.ref == 'refs/heads/master' || github.event.inputs.force_promotion == 'true')
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install uv
          uv venv .venv
          uv pip install -e .
      
      - name: Download staging artifacts
        uses: actions/download-artifact@v4
        with:
          name: staging-artifacts
      
      - name: Promote model to production
        env:
          FORCE_PROMOTION: ${{ github.event.inputs.force_promotion }}
        run: |
          echo "Promoting staging model to production..."
          
          FORCE_FLAG=""
          if [ "$FORCE_PROMOTION" = "true" ]; then
            FORCE_FLAG="--force"
          fi
          
          if uv run python scripts/promote_to_production.py $FORCE_FLAG; then
            echo "Model promoted to production successfully"
          else
            echo "Failed to promote model to production"
            exit 1
          fi
      
      - name: Commit production model updates
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          # Add production model files
          git add models/production_model/
          
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Update production model from CI/CD promotion [skip ci]"
            git push
          fi
      
      - name: Update Docker images with new model
        env:
          DOCKER_HUB_USERNAME: ${{ env.DOCKER_HUB_USERNAME }}
          DOCKER_HUB_TOKEN: ${{ env.DOCKER_HUB_TOKEN }}
        run: |
          echo "Building and pushing updated Docker images..."
          
          # Login to Docker Hub
          echo $DOCKER_HUB_TOKEN | docker login -u $DOCKER_HUB_USERNAME --password-stdin
          
          # Build and push with production model
          export IMAGE_TAG=production-$(date +%Y%m%d-%H%M%S)
          docker compose build
          
          # Tag and push
          docker tag $DOCKER_HUB_USERNAME/mlops-api:latest $DOCKER_HUB_USERNAME/mlops-api:$IMAGE_TAG
          docker push $DOCKER_HUB_USERNAME/mlops-api:latest
          docker push $DOCKER_HUB_USERNAME/mlops-api:$IMAGE_TAG
          
          echo "Docker images updated with production model"
      
      - name: Upload production artifacts
        uses: actions/upload-artifact@v4
        with:
          name: production-artifacts
          path: |
            artifacts/
            logs/
            models/production_model/
          retention-days: 90

  notify-completion:
    runs-on: ubuntu-latest
    name: "Pipeline Completion Notification"
    needs: [data-validation-and-training, promote-to-staging, promote-to-production]
    if: always()
    
    steps:
      - name: Pipeline Summary
        run: |
          echo "=== Data-Driven ML Pipeline Summary ==="
          echo "Training: ${{ needs.data-validation-and-training.result }}"
          echo "Staging: ${{ needs.promote-to-staging.result }}"
          echo "Production: ${{ needs.promote-to-production.result }}"
          
          if [ "${{ needs.promote-to-production.result }}" = "success" ]; then
            echo "üéâ Full pipeline completed successfully!"
            echo "‚úÖ Model trained on updated data"
            echo "‚úÖ Model promoted to staging"  
            echo "‚úÖ Model promoted to production"
            echo "‚úÖ Production model updated"
            echo "‚úÖ Docker images rebuilt"
          elif [ "${{ needs.promote-to-staging.result }}" = "success" ]; then
            echo "‚ö†Ô∏è Pipeline partially completed"
            echo "‚úÖ Model trained and promoted to staging"
            echo "‚ùå Production promotion skipped (not on master branch)"
          else
            echo "‚ùå Pipeline failed"
          fi